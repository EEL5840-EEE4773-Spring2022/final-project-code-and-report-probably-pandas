{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec157994-553f-410f-8d2e-7165a9b91917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries \n",
    "#------------------------------------------------------------------------#\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')\n",
    "import cv2\n",
    "#------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb0c11d-1e29-4b61-872a-565fdf70f9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label names and load data\n",
    "#------------------------------------------------------------------------#\n",
    "labels_names =['a','b','c','d','e','f','g','h','$','#']\n",
    "# Loading Data\n",
    "data_train = np.load('/blue/eee4773/share/data_train.npy')\n",
    "labels_train = np.load('data/correct_labels.npy') # Contains corrected labels\n",
    "#------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d186bc9f",
   "metadata": {},
   "source": [
    "## Create functions for Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a754a",
   "metadata": {},
   "source": [
    "### Binary Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478aee49-3744-471f-9854-1b7e3bb36f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func takes in image and returns the largest contour found with its min enclosing circle inside the image boundary\n",
    "# Contours found after binary thresholding\n",
    "def bint(img):\n",
    "    blurred = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    thresh = cv2.threshold(blurred, 100, 255, cv2.THRESH_BINARY_INV)[1] #100\n",
    "    # thresh = cv2.threshold(blurred,0,255,cv2.THRESH_OTSU+cv2.THRESH_BINARY_INV)[1] \n",
    "    \n",
    "    kernel = np.ones((3,1), np.uint8)\n",
    "    erode = cv2.erode(thresh, kernel, iterations=0)\n",
    "    kernel = np.ones((1,3), np.uint8)\n",
    "    erode = cv2.erode(erode, kernel, iterations=0)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (5,5))\n",
    "    dilate = cv2.dilate(erode, kernel , iterations=1)\n",
    "\n",
    "    # Find contours in the image\n",
    "    cnts = cv2.findContours(dilate.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    bcr = 175\n",
    "    threshold_min_radius = 16\n",
    "    threshold_min_area = 256\n",
    "    mxr = threshold_min_radius\n",
    "    mxa = threshold_min_area\n",
    "    x,y,r = [0]*3\n",
    "    cnt = 0\n",
    "    \n",
    "    for c in cnts:\n",
    "        (cx,cy),cr = cv2.minEnclosingCircle(c)\n",
    "        [cx,cy,cr] = [int(i) for i in [cx,cy,cr]]\n",
    "        (bx,by),(bw,bh),a = cv2.minAreaRect(c)\n",
    "        # area = cv2.contourArea(c)\n",
    "        dis = math.sqrt((cx - 150)**2 + (cy - 150)**2)\n",
    "        overlap =  (dis + cr) <= bcr and dis < 50\n",
    "        inside = (cx - cr) > 0 and (cy - cr) > 0 and (cx + cr) < 300 and (cy + cr) < 300\n",
    "        if cr > threshold_min_radius and (inside or overlap) and bw*bh > mxa and min(bw, bh)/max(bw, bh) > 0.32:\n",
    "            # cv2.drawContours(original_image,[c], 0, (0,255,0), 3)\n",
    "            if True:\n",
    "                cnt = c\n",
    "                mxr = cr\n",
    "                mxa = bw*bh\n",
    "                x,y,r = [int(i) for i in [cx,cy,cr]]\n",
    "        # if area > 10000 and 120 < (bx+bw)/2 < 180 and 120 < (bx+bw)/2 < 180:\n",
    "        #     cv2.rectangle(dilate, (bx,by), (bx+bw,by+bh), (255,255,255),2)\n",
    "    return x,y,r,mxa,cnt\n",
    "#-----------------------------------------------------------------------------------------------------#    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66359f3b",
   "metadata": {},
   "source": [
    "### Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0c4d91-26aa-42f0-9f94-ad61101efa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func takes in image and returns the largest contour found with its min enclosing circle inside the image boundary\n",
    "# Contours found after running edge detection\n",
    "def lint(image):\n",
    "    image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    edges = cv2.Canny(image=image, threshold1=100, threshold2=200)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "    edges = cv2.dilate(edges, kernel , iterations=1)\n",
    "\n",
    "\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, 200, None, 0, 0)\n",
    "\n",
    "    if lines is not None:\n",
    "        for i in range(0, len(lines)):\n",
    "            rho = lines[i][0][0]\n",
    "            theta = lines[i][0][1]\n",
    "            a = math.cos(theta)\n",
    "            b = math.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            pt1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))\n",
    "            pt2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
    "            cv2.line(edges, pt1, pt2, (0,0,0), 2, cv2.LINE_AA)\n",
    "#             cv2.line(pimg, pt1, pt2, (64,64,64), 3, cv2.LINE_AA)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "    imlin = cv2.dilate(edges, kernel , iterations=2)\n",
    "    # Find contours in the image\n",
    "    cnts = cv2.findContours(imlin.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    bcr = 175\n",
    "    threshold_min_radius = 16\n",
    "    threshold_min_area = 256\n",
    "    mxr = threshold_min_radius\n",
    "    mxa = threshold_min_area\n",
    "    x,y,r = [0]*3\n",
    "    cnt = 0\n",
    "    for c in cnts:\n",
    "        (cx,cy),cr = cv2.minEnclosingCircle(c)\n",
    "        [cx,cy,cr] = [int(i) for i in [cx,cy,cr]]\n",
    "        (bx,by),(bw,bh),a = cv2.minAreaRect(c)\n",
    "        # area = cv2.contourArea(c)\n",
    "        dis = math.sqrt((cx - 150)**2 + (cy - 150)**2)\n",
    "        overlap =  (dis + cr) <= bcr and dis < 50\n",
    "        inside = (cx - cr) > 0 and (cy - cr) > 0 and (cx + cr) < 300 and (cy + cr) < 300\n",
    "        if cr > threshold_min_radius and (inside) and bw*bh > mxa and min(bw, bh)/max(bw, bh) > 0.32:\n",
    "            # cv2.drawContours(original_image,[c], 0, (0,255,0), 3)\n",
    "            if True:\n",
    "                cnt = c\n",
    "                mxr = cr\n",
    "                mxa = bw*bh\n",
    "                x,y,r = [int(i) for i in [cx,cy,cr]]\n",
    "        # if area > 10000 and 120 < (bx+bw)/2 < 180 and 120 < (bx+bw)/2 < 180:\n",
    "        #     cv2.rectangle(dilate, (bx,by), (bx+bw,by+bh), (255,255,255),2)\n",
    "    return imlin,lines,x,y,r,mxa,cnt\n",
    "#------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fbfced",
   "metadata": {},
   "source": [
    "### Otsu's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57c03b3-dffd-4a34-bd4a-545cfb1b0d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func takes in image and returns the largest contour found with its min enclosing circle inside the image boundary\n",
    "# Contours found after Otsu's thresholding\n",
    "def otsu(pimg):\n",
    "    blurred = cv2.GaussianBlur(pimg, (3, 3), 0)\n",
    "    thresh = cv2.threshold(blurred,0,255,cv2.THRESH_OTSU+cv2.THRESH_BINARY_INV)[1] \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    imotsu = cv2.dilate(thresh, kernel , iterations=1)\n",
    "\n",
    "    x,y,r = [0]*3\n",
    "    # Find contours in the image\n",
    "    cnts = cv2.findContours(imotsu.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    threshold_min_radius = 13\n",
    "    threshold_min_area = 256\n",
    "    mxr = threshold_min_radius\n",
    "    mxa = threshold_min_area\n",
    "    x,y,r = [0]*3\n",
    "    cnt = 0\n",
    "    for c in cnts:\n",
    "        (cx,cy),cr = cv2.minEnclosingCircle(c)\n",
    "        [cx,cy,cr] = [int(i) for i in [cx,cy,cr]]\n",
    "        (bx,by),(bw,bh),a = cv2.minAreaRect(c)\n",
    "        # if cr > 100 and 200 < cx < 100 and 200 < cy < 100:\n",
    "        #     continue\n",
    "        inside = (cx - cr) > 0 and (cy - cr) > 0 and (cx + cr) < 300 and (cy + cr) < 300\n",
    "        if cr > mxr and inside and bw*bh > 1600 and min(bw, bh)/max(bw, bh) > 0.25:\n",
    "            # cv2.drawContours(original_image,[c], 0, (0,255,0), 3)\n",
    "            if True:\n",
    "                cnt = c\n",
    "                mxr = cr\n",
    "                mxa = bw*bh\n",
    "                x,y,r = [cx,cy,cr]\n",
    "    return imotsu,x,y,r,mxa,cnt\n",
    "#------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d8d9b",
   "metadata": {},
   "source": [
    "### Combining the three Data Augmentation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece722a5-f68f-4ed5-b1bf-f4293220cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augmentation\n",
    "#function takes in data and labels\n",
    "#data augmentation:\n",
    "#1. Original image\n",
    "#2. Crop- take the largest bounding box from the three contours defined above\n",
    "#3. Crop same location on the original image\n",
    "#4. Horizontal flips for the step 1, 2, 3 images\n",
    "#5. Translate images from above steps when in training mode\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "#------------------------------------------------------------------------#\n",
    "def augment_data(data_train, labels_train, train=False, imsize=300):\n",
    "    data = []\n",
    "    labels = []\n",
    "    k = 1000\n",
    "    for t in range(len(data_train)):\n",
    "        res = []\n",
    "        img = np.copy(data_train[t].reshape((imsize,imsize)))\n",
    "        pimg = np.copy(data_train[t].reshape((imsize,imsize)))\n",
    "        image = np.copy(data_train[t].reshape(imsize, imsize))\n",
    "\n",
    "        imlin,lines,x,y,r,mxa,cnt = lint(image)\n",
    "        lincon = cnt\n",
    "    #         cv2.circle(edges, (x,y), r, (255,255,255),2)\n",
    "        res.append((x,y,r,mxa))\n",
    "\n",
    "\n",
    "\n",
    "        blurred = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "        thresh = cv2.threshold(blurred, 100, 255, cv2.THRESH_BINARY_INV)[1] #100\n",
    "        # thresh = cv2.threshold(blurred,0,255,cv2.THRESH_OTSU+cv2.THRESH_BINARY_INV)[1] \n",
    "        kernel = np.ones((3,1), np.uint8)\n",
    "        erode = cv2.erode(thresh, kernel, iterations=0)\n",
    "        kernel = np.ones((1,3), np.uint8)\n",
    "        erode = cv2.erode(erode, kernel, iterations=0)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (5,5))\n",
    "        imbin = cv2.dilate(erode, kernel , iterations=1)\n",
    "\n",
    "\n",
    "        x,y,r,mxa,cnt = bint(img)\n",
    "        if r == 0:\n",
    "            img = np.copy(data_train[t].reshape((imsize,imsize)))\n",
    "            img = np.roll(img, 25, axis=0)\n",
    "            x,y,r,mxa,cnt = bint(img)\n",
    "            if r != 0: y -= 25\n",
    "        if r == 0:\n",
    "            img = np.copy(data_train[t].reshape((imsize,imsize)))\n",
    "            img = np.roll(img, -25, axis=0)\n",
    "            x,y,r,mxa,cnt = bint(img)\n",
    "            if r != 0: y += 25\n",
    "        if r == 0:\n",
    "            img = np.copy(data_train[t].reshape((imsize,imsize)))\n",
    "            img = np.roll(img, 25, axis=1)\n",
    "            x,y,r,mxa,cnt = bint(img)\n",
    "            if r != 0: x -= 25\n",
    "        if r == 0:\n",
    "            img = np.copy(data_train[t].reshape((imsize,imsize)))\n",
    "            img = np.roll(img, -25, axis=1)\n",
    "            x,y,r,mxa,cnt = bint(img)\n",
    "            if r != 0: x += 25\n",
    "\n",
    "        bincon = cnt\n",
    "    #         cv2.circle(dilate, (x,y), r, (255,255,255),2)\n",
    "        res.append((x,y,r,mxa))\n",
    "\n",
    "\n",
    "        imotsu,x,y,r,mxa,cnt = otsu(pimg)\n",
    "        otsucon = cnt\n",
    "    #         cv2.circle(dilate, (x,y), r, (255,255,255),2)\n",
    "        # cv2.drawContours(pimg,[cnt], 0, (0,255,0), 3)\n",
    "        # cv2.rectangle(pimg, (x-r,y-r), (x+r, y+r), (0,255,0),1)\n",
    "        res.append((x,y,r,mxa))\n",
    "\n",
    "        edge_x, edge_y, edge_r, edge_a = res[0]\n",
    "        bin_x, bin_y, bin_r, bin_a = res[1]\n",
    "        otsu_x, otsu_y, otsu_r, otsu_a = res[2]\n",
    "        x,y,r = (150,150,150)\n",
    "        found = res != [(0,0,0,256), (0,0,0,256), (0,0,0,256)]\n",
    "        con = bincon\n",
    "        img = imbin\n",
    "    #     ax = fig.add_subplot(100,10,t+1)\n",
    "        x,y,s = (0,0,300)\n",
    "        if found:\n",
    "            if otsu_a > bin_a:\n",
    "                con = otsucon\n",
    "                img = imotsu\n",
    "            oa = 0\n",
    "            if bin_a == 256 and otsu_a == 256:\n",
    "                oa = 1\n",
    "            if edge_a > bin_a and edge_a > otsu_a and (oa > 0.75 or lines is None):\n",
    "                con = lincon\n",
    "                img = imlin\n",
    "            if con is bincon:\n",
    "                x,y,w,h = bin_x-bin_r, bin_y-bin_r, 2*bin_r, 2*bin_r\n",
    "            else:\n",
    "                x,y,w,h = cv2.boundingRect(con)\n",
    "            s = 0\n",
    "            if h > w:\n",
    "                y -= 10\n",
    "                h += 20\n",
    "                x = x + w//2 - h//2\n",
    "                s = h\n",
    "            else:\n",
    "                x -= 10\n",
    "                w += 20\n",
    "                y = y + h//2 - w//2\n",
    "                s = w\n",
    "            x = x if x > 0 else 0\n",
    "            y = y if y > 0 else 0\n",
    "            s = s if s < 300 else 300\n",
    "    #         im = cv2.cvtColor(data_train[:,t+j*100].reshape((300,300)), cv2.COLOR_GRAY2BGR)\n",
    "    #         cv2.rectangle(im, (x,y), (x+s, y+s), (0,0,0),2)\n",
    "\n",
    "    #         x,y,w,h = cv2.boundingRect(lincon) if edge_a > 256 else (0,0,300,300)\n",
    "    #         cv2.rectangle(im, (x,y), (x+w, y+h), (255,0,0),2)\n",
    "    #         x,y,w,h = cv2.boundingRect(bincon) if bin_a > 256 else (0,0,300,300)\n",
    "    #         cv2.rectangle(im, (x,y), (x+w, y+h), (0,255,0),2)\n",
    "    #         x,y,w,h = cv2.boundingRect(otsucon) if otsu_a > 256 else (0,0,300,300)\n",
    "    #         cv2.rectangle(im, (x,y), (x+w, y+h), (0,0,255),2)\n",
    "\n",
    "\n",
    "        im = np.copy(data_train[t].reshape((imsize,imsize)))\n",
    "        char = cv2.resize(im[y:y+s, x:x+s],(50,50),interpolation = cv2.INTER_AREA).astype(np.uint8)\n",
    "        char = np.invert(char.astype(np.uint8))\n",
    "\n",
    "        ud = char\n",
    "        du = np.flip(ud)\n",
    "        data.append(ud)\n",
    "        data.append(du)\n",
    "        labels.append(labels_train[t])\n",
    "        labels.append(labels_train[t])\n",
    "        if train:\n",
    "            sh = np.roll(ud, (2*npr.randint(0, 1)-1)*5, axis=0)\n",
    "            sh = np.roll(sh, (2*npr.randint(0, 1)-1)*5, axis=1)\n",
    "            data.append(sh)\n",
    "            sh = np.roll(du, (2*npr.randint(0, 1)-1)*5, axis=0)\n",
    "            sh = np.roll(sh, (2*npr.randint(0, 1)-1)*5, axis=1)\n",
    "            data.append(sh)\n",
    "            labels.append(labels_train[t])\n",
    "            labels.append(labels_train[t])\n",
    "\n",
    "        \n",
    "        if s < 300:   \n",
    "            ud = cv2.resize(img[y:y+s, x:x+s],(50,50),interpolation = cv2.INTER_AREA).astype(np.uint8)\n",
    "        du = np.flip(ud)\n",
    "        data.append(ud)\n",
    "        data.append(du)\n",
    "        labels.append(labels_train[t])\n",
    "        labels.append(labels_train[t])\n",
    "        if train:\n",
    "            sh = np.roll(ud, (2*npr.randint(0, 1)-1)*5, axis=0)\n",
    "            sh = np.roll(sh, (2*npr.randint(0, 1)-1)*5, axis=1)\n",
    "            data.append(sh)\n",
    "            sh = np.roll(du, (2*npr.randint(0, 1)-1)*5, axis=0)\n",
    "            sh = np.roll(sh, (2*npr.randint(0, 1)-1)*5, axis=1)\n",
    "            data.append(sh)\n",
    "            labels.append(labels_train[t])\n",
    "            labels.append(labels_train[t])\n",
    "\n",
    "\n",
    "        ud = cv2.resize(im,(50,50),interpolation = cv2.INTER_AREA).astype(np.uint8)\n",
    "        du = np.flip(ud)\n",
    "        data.append(ud)\n",
    "        data.append(du)\n",
    "        labels.append(labels_train[t])\n",
    "        labels.append(labels_train[t])\n",
    "        if train:\n",
    "            sh = np.roll(ud, (2*npr.randint(0, 1)-1)*5, axis=0)\n",
    "            sh = np.roll(sh, (2*npr.randint(0, 1)-1)*5, axis=1)\n",
    "            data.append(sh)\n",
    "            sh = np.roll(du, (2*npr.randint(0, 1)-1)*5, axis=0)\n",
    "            sh = np.roll(sh, (2*npr.randint(0, 1)-1)*5, axis=1)\n",
    "            data.append(sh)\n",
    "            labels.append(labels_train[t])\n",
    "            labels.append(labels_train[t])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     plt.imshow(char, cmap='gray') \n",
    "    return np.array(data), np.array(labels)\n",
    "#------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc47468",
   "metadata": {},
   "source": [
    "### Get training data post augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001c0ce2-b14a-43e1-856f-5f26be3520eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = augment_data(data_train.T, labels_train, train=True)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2dbe07",
   "metadata": {},
   "source": [
    "### Add additional samples using EMNIST Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40173a-1a15-4d86-bd6a-6b9c6928a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EMNIST Balanced Dataset\n",
    "#Add numbers and capital letters from this dataset for training\n",
    "#Numbers and any characters which were not in the collected dataset set to class -1\n",
    "#Remove numbers 3,4,6,9 due to similarity with collected data\n",
    "df=pd.read_csv('data/emnist-balanced-test.csv')\n",
    "\n",
    "exlabel = df['41'].to_numpy()\n",
    "df = df.drop(columns=['41'])\n",
    "exdata = df.to_numpy().astype(np.float32)\n",
    "\n",
    "exdata = exdata[exlabel != 3]\n",
    "exlabel = exlabel[exlabel != 3]\n",
    "exdata = exdata[exlabel != 4]\n",
    "exlabel = exlabel[exlabel != 4]\n",
    "\n",
    "exdata = exdata[exlabel != 6]\n",
    "exlabel = exlabel[exlabel != 6]\n",
    "exdata = exdata[exlabel != 9]\n",
    "exlabel = exlabel[exlabel != 9]\n",
    "\n",
    "exdata = exdata[exlabel < 36]\n",
    "exlabel = exlabel[exlabel < 36]\n",
    "\n",
    "exlabel[exlabel <= 9] = -1\n",
    "exlabel[exlabel >= 20] = -1\n",
    "\n",
    "exdata = exdata[exlabel < 18]\n",
    "exlabel = exlabel[exlabel < 18]\n",
    "exlabel[exlabel > 9] -= 10\n",
    "exlabel[exlabel < 0] = 10\n",
    "\n",
    "#------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315c0987-be7e-4ac1-bb02-a98a1656c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upscale EMNIST images to 50x50\n",
    "ex = []\n",
    "for t in range(len(exdata)):\n",
    "    ex.append(cv2.resize(exdata[t].reshape((28,28)), (50,50), interpolation = cv2.INTER_CUBIC).astype(np.uint8))\n",
    "exdata = np.array(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5cb8df",
   "metadata": {},
   "source": [
    "### Combining training data and EMNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53221ea-a1db-4973-adf9-4098facc8f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack((X_train, exdata))\n",
    "y_train = np.concatenate((y_train, exlabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904caf4",
   "metadata": {},
   "source": [
    "### One-hot encode the labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b5ffa1-1421-4552-a9d3-b21683df1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "def preprocess_data(X, y,imsize=50):\n",
    "#   # reshape images to the required size of Keras\n",
    "    X = X.reshape(X.shape[0], imsize, imsize, 1)\n",
    "\n",
    "    # convert image values from integers to floats\n",
    "    X = X.astype('float32')\n",
    "\n",
    "    # normalization\n",
    "    X = X/255.0\n",
    "\n",
    "    # One-hot encoding label \n",
    "    y = to_categorical(y)\n",
    "\n",
    "    return X, y\n",
    "#------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d35f5",
   "metadata": {},
   "source": [
    "## Creating CConvolutional Neural Net for character recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec5484e-661b-4c91-a058-19604dbb1397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def PandaNet(input_shape):\n",
    "    model = Sequential([\n",
    "    tf.keras.Input(shape=input_shape),\n",
    "    Conv2D(16, (5, 5), activation='relu', padding = 'same', kernel_initializer='he_uniform'),\n",
    "    MaxPooling2D((2, 2), strides=(2)),\n",
    "\n",
    "    Conv2D(32, (5,5),activation='relu', kernel_initializer='he_uniform'),\n",
    "    MaxPooling2D((2, 2), strides=(2)),\n",
    "\n",
    "    Conv2D(64,(3,3), activation='relu', kernel_initializer='he_uniform'),\n",
    "    MaxPooling2D((2, 2), strides=(2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation='relu', kernel_initializer='he_uniform', kernel_regularizer='l2'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer='l2'),\n",
    "    Dropout(0.2),\n",
    "    Dense(11, activation='softmax')\n",
    "    ])\n",
    "    # compile model\n",
    "    opt = Adam(learning_rate=0.0001 , epsilon=1e-5)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "#------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e03a511",
   "metadata": {},
   "source": [
    "### Define fucntions to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdece4c-096b-44f4-8323-325d6142dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------#\n",
    "def summary_history(history):\n",
    "    plt.figure(figsize = (10,6))\n",
    "    plt.plot(history.history['accuracy'], color = 'blue', label = 'train')\n",
    "    plt.plot(history.history['val_accuracy'], color = 'red', label = 'val')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy')\n",
    "    plt.show()\n",
    "#------------------------------------------------------------------------#\n",
    "def train(model, X_train, y_train, epochs = 50, batch_size = 128):\n",
    "    # Rescaling all training and testing data\n",
    "    X_train, y_train = preprocess_data(X_train, y_train)\n",
    "    # Fitting the model on the training set\n",
    "    history = model.fit(X_train, y_train, epochs = epochs,\n",
    "                        validation_split=0.2, batch_size = batch_size, verbose = 1)\n",
    "    return history\n",
    "#------------------------------------------------------------------------#\n",
    "def test_model(model, X_test, y_test, evalualte=False):\n",
    "    # Rescaling all training and testing data\n",
    "    X_test, y_test = preprocess_data(X_test, y_test)\n",
    "\n",
    "    # Fitting the model on the training set\n",
    "    pred = model.predict(X_test)\n",
    "    return pred\n",
    "#------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7843ca",
   "metadata": {},
   "source": [
    "### Model Summary and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20383b89-98e7-41cc-b5ae-7dc71ffd1933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = PandaNet(input_shape=(50,50, 1))\n",
    "print(model.summary())\n",
    "#------------------------------------------------------------------------#\n",
    "\n",
    "# training \n",
    "hist = train(model, X_train,y_train, 256,64)\n",
    "#------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7fe7c8-74ad-4f58-b4b7-ca5082832cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "#------------------------------------------------------------------------#\n",
    "model.save('PandaNet')\n",
    "#------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd454e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize training and validation loss\n",
    "#------------------------------------------------------------------------#\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['loss'],marker='*', label='train - CNN')\n",
    "plt.plot(history.history['val_loss'],marker='.', label='Validation - CNN')\n",
    "plt.title('Training Results - CNN')\n",
    "plt.legend();\n",
    "#------------------------------------------------------------------------#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
